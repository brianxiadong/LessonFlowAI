---
name: tts-voice
description: ä½¿ç”¨é˜¿é‡Œäº‘ TTS ç”Ÿæˆé…éŸ³ï¼Œæ”¯æŒå­—çº§æ—¶é—´æˆ³å’Œ SSML æ§åˆ¶
---

# é…éŸ³ç”Ÿæˆ Skill (Voice)

## æ¦‚è¿°

æ­¤ Skill è´Ÿè´£ä½¿ç”¨é˜¿é‡Œäº‘æ™ºèƒ½è¯­éŸ³äº¤äº’æœåŠ¡ç”Ÿæˆé«˜è´¨é‡é…éŸ³ï¼Œæ”¯æŒï¼š
- å­—çº§æ—¶é—´æˆ³ï¼ˆç”¨äºç²¾å‡†å­—å¹•å¯¹é½ï¼‰
- SSML æ ‡è®°ï¼ˆæ§åˆ¶è¯­é€Ÿã€åœé¡¿ã€æœ¯è¯­å‘éŸ³ï¼‰
- å¤šç§éŸ³è‰²é€‰æ‹©
- éŸ³é¢‘åå¤„ç†ï¼ˆå“åº¦æ ‡å‡†åŒ–ï¼‰

## è§¦å‘æ¡ä»¶

- å‰ç½®æ¡ä»¶ï¼š`storyboard.json` å’Œ `glossary.json` å·²å­˜åœ¨
- è§¦å‘æ–¹å¼ï¼š
  - è‡ªåŠ¨ï¼šOrchestrator è°ƒç”¨
  - æ‰‹åŠ¨ï¼šç”¨æˆ·è¯´ "ç”Ÿæˆé…éŸ³" / "TTS"

## è¾“å…¥

```
courses/[lesson_id]/
  storyboard.json    # æ¯ä¸ªåœºæ™¯çš„ narration.vo_text
  glossary.json      # æœ¯è¯­å‘éŸ³è¡¨
```

## è¾“å‡º

```
courses/[lesson_id]/
  audio/
    scene_001.wav
    scene_001_timestamps.json
    scene_002.wav
    scene_002_timestamps.json
    ...
  logs/
    tts_cost.log     # è´¹ç”¨ç»Ÿè®¡
```

## é˜¿é‡Œäº‘ TTS é…ç½®

### å¼€é€šæœåŠ¡

1. è®¿é—® [é˜¿é‡Œäº‘æ™ºèƒ½è¯­éŸ³äº¤äº’æ§åˆ¶å°](https://nls-portal.console.aliyun.com/)
2. å¼€é€šã€Œè¯­éŸ³åˆæˆã€æœåŠ¡
3. åˆ›å»ºé¡¹ç›®ï¼Œè·å– AppKey
4. è·å– AccessKey ID å’Œ Secret

### ç¯å¢ƒå˜é‡é…ç½®

```bash
export ALIYUN_ACCESS_KEY_ID="your_access_key_id"
export ALIYUN_ACCESS_KEY_SECRET="your_access_key_secret"
export ALIYUN_TTS_APP_KEY="your_app_key"
```

### å¯ç”¨éŸ³è‰²

| éŸ³è‰²å | è¯­è¨€ | é£æ ¼ | æ¨èåœºæ™¯ |
|--------|------|------|----------|
| zhitian_emo | ä¸­æ–‡ | æƒ…æ„Ÿå¥³å£° | æ•™å­¦è®²è§£ |
| zhiyan_emo | ä¸­æ–‡ | æƒ…æ„Ÿå¥³å£° | æ•…äº‹å™è¿° |
| zhigui | ä¸­æ–‡ | ç”·å£° | æ–°é—»æ’­æŠ¥ |
| xiaoyun | ä¸­æ–‡ | æ ‡å‡†å¥³å£° | é€šç”¨ |
| kenny | è‹±æ–‡ | ç”·å£° | è‹±è¯­æ•™å­¦ |

## æ‰§è¡Œæ­¥éª¤

### æ­¥éª¤ 1ï¼šè´¹ç”¨é¢„ä¼°

**é‡è¦**ï¼šåœ¨ç”Ÿæˆå‰å…ˆä¼°ç®—è´¹ç”¨ï¼Œé¿å…æ„å¤–æ¶ˆè´¹ã€‚

```python
def estimate_tts_cost(storyboard: dict) -> dict:
    """
    ä¼°ç®— TTS è´¹ç”¨
    é˜¿é‡Œäº‘å®šä»·: çº¦ Â¥2/ä¸‡å­—ç¬¦ï¼ˆä»¥å®é™…å®šä»·ä¸ºå‡†ï¼‰
    """
    total_chars = 0
    
    for scene in storyboard["scenes"]:
        vo_text = scene.get("narration", {}).get("vo_text", "")
        total_chars += len(vo_text)
    
    # è´¹ç‡ï¼ˆå…ƒ/ä¸‡å­—ç¬¦ï¼‰
    rate = 2.0
    estimated_cost = (total_chars / 10000) * rate
    
    return {
        "total_characters": total_chars,
        "estimated_cost_cny": round(estimated_cost, 2),
        "rate": f"Â¥{rate}/ä¸‡å­—ç¬¦"
    }
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ“Š TTS è´¹ç”¨é¢„ä¼°
   æ€»å­—ç¬¦æ•°: 2,850
   é¢„ä¼°è´¹ç”¨: Â¥0.57
   è®¡è´¹æ ‡å‡†: Â¥2/ä¸‡å­—ç¬¦

ç¡®è®¤ç”Ÿæˆ? (y/n)
```

### æ­¥éª¤ 2ï¼šå‡†å¤‡ SSML æ–‡æœ¬

å°†æ™®é€šæ–‡æœ¬è½¬æ¢ä¸ºå¸¦ SSML æ ‡è®°çš„æ–‡æœ¬ï¼š

```python
def prepare_ssml(text: str, glossary: dict, config: dict) -> str:
    """
    å‡†å¤‡ SSML æ–‡æœ¬
    - æ›¿æ¢æœ¯è¯­å‘éŸ³
    - æ·»åŠ åœé¡¿æ ‡è®°
    - è®¾ç½®è¯­é€Ÿ
    """
    ssml_text = text
    
    # æ›¿æ¢æœ¯è¯­å‘éŸ³
    for term, info in glossary.get("terms", {}).items():
        if term in ssml_text and "ssml" in info:
            ssml_text = ssml_text.replace(term, info["ssml"])
        elif term in ssml_text and "alias" in info:
            # ä½¿ç”¨åˆ«åæ›¿æ¢ï¼ˆè®© TTS è¯»ä¸­æ–‡ï¼‰
            ssml_text = ssml_text.replace(term, info["alias"])
    
    # åœ¨æ ‡ç‚¹åæ·»åŠ åœé¡¿
    ssml_text = ssml_text.replace("ã€‚", 'ã€‚<break time="300ms"/>')
    ssml_text = ssml_text.replace("ï¼Œ", 'ï¼Œ<break time="150ms"/>')
    
    # åŒ…è£…ä¸º SSML
    speed = config.get("speed", 1.0)
    ssml = f'''<speak>
    <prosody rate="{speed}">
        {ssml_text}
    </prosody>
</speak>'''
    
    return ssml
```

**SSML ç¤ºä¾‹**ï¼š

åŸå§‹æ–‡æœ¬ï¼š
```
Attention æ˜¯ Transformer çš„æ ¸å¿ƒæœºåˆ¶ã€‚
```

è½¬æ¢åï¼š
```xml
<speak>
    <prosody rate="1.0">
        <phoneme alphabet="ipa" ph="É™ËˆtenÊƒÉ™n">Attention</phoneme> æ˜¯ 
        <phoneme alphabet="ipa" ph="ËˆtrÃ¦nsËŒfÉ”rmÉ™r">Transformer</phoneme> çš„æ ¸å¿ƒæœºåˆ¶ã€‚
        <break time="300ms"/>
    </prosody>
</speak>
```

### æ­¥éª¤ 3ï¼šè°ƒç”¨é˜¿é‡Œäº‘ TTS API

```python
import nls
import json
from pathlib import Path

class AliyunTTS:
    def __init__(self, access_key_id, access_key_secret, app_key):
        self.token = self._get_token(access_key_id, access_key_secret)
        self.app_key = app_key
    
    def synthesize(
        self,
        text: str,
        output_path: str,
        voice: str = "zhitian_emo",
        format: str = "wav",
        sample_rate: int = 16000,
        enable_subtitle: bool = True
    ) -> dict:
        """
        åˆæˆè¯­éŸ³å¹¶è¿”å›æ—¶é—´æˆ³
        """
        timestamps = []
        audio_data = bytearray()
        
        def on_data(data, *args):
            audio_data.extend(data)
        
        def on_message(message, *args):
            msg = json.loads(message)
            if "payload" in msg and "subtitles" in msg["payload"]:
                timestamps.extend(msg["payload"]["subtitles"])
        
        synthesizer = nls.NlsSpeechSynthesizer(
            token=self.token,
            appkey=self.app_key,
            on_data=on_data,
            on_message=on_message
        )
        
        synthesizer.start(
            text=text,
            voice=voice,
            format=format,
            sample_rate=sample_rate,
            enable_subtitle=enable_subtitle
        )
        
        # ä¿å­˜éŸ³é¢‘
        with open(output_path, "wb") as f:
            f.write(audio_data)
        
        # ä¿å­˜æ—¶é—´æˆ³
        timestamp_path = output_path.replace(".wav", "_timestamps.json")
        with open(timestamp_path, "w", encoding="utf-8") as f:
            json.dump({"subtitles": timestamps}, f, ensure_ascii=False, indent=2)
        
        return {
            "audio_path": output_path,
            "timestamps_path": timestamp_path,
            "duration_ms": timestamps[-1]["end_time"] if timestamps else 0,
            "subtitle_count": len(timestamps)
        }
```

### æ­¥éª¤ 4ï¼šéŸ³é¢‘åå¤„ç†

**å“åº¦æ ‡å‡†åŒ–ï¼ˆLUFSï¼‰**ï¼š

```python
from pydub import AudioSegment
from pydub.effects import normalize

def normalize_audio(input_path: str, output_path: str, target_lufs: float = -16.0):
    """
    å“åº¦æ ‡å‡†åŒ–
    target_lufs: ç›®æ ‡å“åº¦ï¼ˆ-16 LUFS æ˜¯å¸¸è§æ ‡å‡†ï¼‰
    """
    audio = AudioSegment.from_wav(input_path)
    
    # æ ‡å‡†åŒ–
    normalized = normalize(audio)
    
    # å¯¼å‡º
    normalized.export(output_path, format="wav")
    
    return output_path
```

**é™éŸ³å¤„ç†**ï¼š

```python
def add_silence(audio_path: str, before_ms: int = 0, after_ms: int = 500):
    """åœ¨éŸ³é¢‘å‰åæ·»åŠ é™éŸ³"""
    audio = AudioSegment.from_wav(audio_path)
    
    silence_before = AudioSegment.silent(duration=before_ms)
    silence_after = AudioSegment.silent(duration=after_ms)
    
    result = silence_before + audio + silence_after
    result.export(audio_path, format="wav")
```

### æ­¥éª¤ 5ï¼šæ‰¹é‡ç”Ÿæˆ

```python
def generate_all_voice(lesson_path: Path, storyboard: dict, glossary: dict):
    """ä¸ºæ‰€æœ‰åœºæ™¯ç”Ÿæˆé…éŸ³"""
    
    tts = AliyunTTS(
        access_key_id=os.getenv("ALIYUN_ACCESS_KEY_ID"),
        access_key_secret=os.getenv("ALIYUN_ACCESS_KEY_SECRET"),
        app_key=os.getenv("ALIYUN_TTS_APP_KEY")
    )
    
    audio_dir = lesson_path / "audio"
    audio_dir.mkdir(exist_ok=True)
    
    results = []
    total_cost = 0
    
    for scene in storyboard["scenes"]:
        scene_id = scene["id"]
        narration = scene.get("narration", {})
        vo_text = narration.get("vo_text", "")
        
        if not vo_text:
            continue
        
        # å‡†å¤‡ SSML
        ssml_text = prepare_ssml(vo_text, glossary, narration)
        
        # åˆæˆ
        output_path = str(audio_dir / f"{scene_id}.wav")
        result = tts.synthesize(
            text=ssml_text,
            output_path=output_path,
            voice=narration.get("voice", "zhitian_emo")
        )
        
        # åå¤„ç†
        normalize_audio(output_path, output_path)
        add_silence(
            output_path,
            before_ms=int(narration.get("pause_before_s", 0) * 1000),
            after_ms=int(narration.get("pause_after_s", 0.5) * 1000)
        )
        
        results.append({
            "scene_id": scene_id,
            **result
        })
        
        total_cost += len(vo_text)
    
    # è®°å½•è´¹ç”¨
    cost_log = lesson_path / "logs" / "tts_cost.log"
    cost_log.parent.mkdir(exist_ok=True)
    with open(cost_log, "w") as f:
        f.write(f"æ€»å­—ç¬¦æ•°: {total_cost}\n")
        f.write(f"é¢„ä¼°è´¹ç”¨: Â¥{total_cost / 10000 * 2:.2f}\n")
    
    return results
```

### æ­¥éª¤ 6ï¼šå¢é‡æ›´æ–°æ”¯æŒ

åªä¸º hash å˜åŒ–çš„åœºæ™¯é‡æ–°ç”Ÿæˆé…éŸ³ï¼š

```python
for scene in storyboard["scenes"]:
    scene_id = scene["id"]
    
    # è®¡ç®— narration hash
    narration_hash = hash(json.dumps(scene.get("narration", {})))
    cached_hash = build_cache.get(scene_id, {}).get("narration_hash")
    
    audio_file = audio_dir / f"{scene_id}.wav"
    
    if narration_hash != cached_hash or not audio_file.exists():
        # éœ€è¦é‡æ–°ç”Ÿæˆ
        generate_voice(scene)
        print(f"ğŸ”„ é‡æ–°ç”Ÿæˆé…éŸ³: {scene_id}")
    else:
        print(f"â­ï¸ è·³è¿‡ï¼ˆæœªå˜æ›´ï¼‰: {scene_id}")
```

## è¾“å‡ºç¡®è®¤

```
âœ… é…éŸ³ç”Ÿæˆå®Œæˆï¼
ğŸ“ è¾“å‡ºç›®å½•: courses/lesson_001/audio/
ğŸ™ï¸ éŸ³é¢‘æ–‡ä»¶:
   - scene_001.wav (10.2s, 16kHz)
   - scene_001_timestamps.json (42 ä¸ªæ—¶é—´ç‚¹)
   - scene_002.wav (12.5s, 16kHz) ğŸ”„ æ–°ç”Ÿæˆ
   - scene_003.wav â­ï¸ è·³è¿‡

ğŸ’° è´¹ç”¨ç»Ÿè®¡:
   æœ¬æ¬¡ç”Ÿæˆå­—ç¬¦æ•°: 1,250
   æœ¬æ¬¡è´¹ç”¨: Â¥0.25
   ç´¯è®¡è´¹ç”¨: Â¥0.57

ä¸‹ä¸€æ­¥: è¿è¡Œ Skill 4 (Subtitles) ç”Ÿæˆå­—å¹•
```

## é”™è¯¯å¤„ç†

| é”™è¯¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| `InvalidToken` | Token è¿‡æœŸ | é‡æ–°è·å– Token |
| `QuotaExhausted` | é…é¢ç”¨å°½ | æ£€æŸ¥è´¦æˆ·ä½™é¢æˆ–æå‡é…é¢ |
| `InvalidParameter` | SSML è¯­æ³•é”™è¯¯ | æ£€æŸ¥ SSML æ ‡è®° |
| `AudioTooLong` | æ–‡æœ¬è¿‡é•¿ | æ‹†åˆ†ä¸ºå¤šæ®µåˆæˆ |

## æœ¬åœ°æµ‹è¯•ï¼ˆå…è´¹æ–¹æ¡ˆï¼‰

å¦‚éœ€æœ¬åœ°æµ‹è¯•ä¸æ¶ˆè€—é˜¿é‡Œäº‘é…é¢ï¼Œå¯ä½¿ç”¨ edge-ttsï¼š

```python
# ä»…ç”¨äºæµ‹è¯•ï¼Œæ— æ—¶é—´æˆ³
import edge_tts

async def test_tts(text: str, output_path: str):
    communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
    await communicate.save(output_path)
```

æ³¨æ„ï¼šedge-tts ä¸æä¾›å­—çº§æ—¶é—´æˆ³ï¼Œæ­£å¼ä½¿ç”¨éœ€é˜¿é‡Œäº‘æœåŠ¡ã€‚
